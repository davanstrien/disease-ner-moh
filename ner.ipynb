{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import spacy\n",
    "from pathlib import Path\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from utils import files_for_year\n",
    "from utils import read_files_for_year\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ner model \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('Full_text/Acton.1893.b19783280.txt')\n",
    "acton_1893 = open(PATH).read()\n",
    "doc = nlp(acton_1893)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the default NER model from spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I. A.R.332 PERSON\n",
      "BS X ORG\n",
      "ACTION LOCAL BOARD ORG\n",
      "THE Medical Officer ORG\n",
      "the year 1893 DATE\n",
      "the ACTON VALE PRINTING PRESS ORG\n",
      "Acton Vale GPE\n",
      "W. ACT PERSON\n",
      "ACTON LOCAL BOARD ORG\n",
      "THE Medical Officer ORG\n",
      "the year 1893 DATE\n",
      "the ACTON VALE PRINTING PRESS ORG\n",
      "Acton Vale GPE\n",
      "W. Acton Local Board ORG\n",
      "Officer of Health ORG\n",
      "the year 1893 DATE\n",
      "the Acton Local Board ORG\n",
      "Acton GPE\n",
      "the year 1893 DATE\n",
      "first ORDINAL\n",
      "Acton GPE\n",
      "Sanitary Science PERSON\n",
      "1884 DATE\n",
      "1885 & 1886 DATE\n",
      "1885 DATE\n",
      "1885 DATE\n",
      "1886 1887 DATE\n",
      "1888 DATE\n",
      "1889 DATE\n",
      "1890 DATE\n"
     ]
    }
   ],
   "source": [
    "def print_ents(ent_number=20):\n",
    "    count = 0 \n",
    "    for ent in doc.ents:\n",
    "        if count < ent_number:\n",
    "            print(ent.text, ent.label_)\n",
    "            count += 1\n",
    "print_ents(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a good starting point but we might also want to have some additional entities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new entity type for diseases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare some data for annotation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Dataturk website to create annotations \n",
    "\n",
    "I created a small [training set](https://dataturks.com/projects/davanstrien/MOH%201895%20full%20text/export). I only used on report to see how the model might work (probably not very well). If we want to do this properly we will need to also create a validation set and think more about whether we want out model to perform well for only one entity or multiple entities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into spacy format using script provides by [Dataturk](https://dataturks.com/help/dataturks-ner-json-to-spacy-train.php) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    try:\n",
    "        training_data = []\n",
    "        lines=[]\n",
    "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data['content']\n",
    "            entities = []\n",
    "            for annotation in data['annotation']:\n",
    "                #only a single point in text annotation.\n",
    "                point = annotation['points'][0]\n",
    "                labels = annotation['label']\n",
    "                # handle both list of labels or a single label.\n",
    "                if not isinstance(labels, list):\n",
    "                    labels = [labels]\n",
    "\n",
    "                for label in labels:\n",
    "                    #dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
    "                    entities.append((point['start'], point['end'] + 1 ,label))\n",
    "\n",
    "\n",
    "            training_data.append((text, {\"entities\" : entities}))\n",
    "\n",
    "        return training_data\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
    "return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = convert_dataturks_to_spacy('ner_tags.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model on our annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "# new entity label\n",
    "LABEL = 'Disease'\n",
    "OUTDIR = Path('models/')\n",
    "# training data\n",
    "# Note: If you're using an existing model, make sure to mix in examples of\n",
    "# other entity types that spaCy correctly recognized before. Otherwise, your\n",
    "# model might learn the new type, but \"forget\" what it previously knew.\n",
    "# https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting\n",
    "TRAIN_DATA = annotations\n",
    "\n",
    "\n",
    "def train_ner(model=None, new_model_name='disease', output_dir=OUTDIR, n_iter=10):\n",
    "    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank('en')  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    # Add entity recognizer to model if it's not in the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    ner.add_label(LABEL)   # add new entity label to entity recognizer\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        # Note that 'begin_training' initializes the models, so it'll zero out\n",
    "        # existing entity types.\n",
    "        optimizer = nlp.entity.create_optimizer()\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(TRAIN_DATA, size=compounding(4., 32., 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35,\n",
    "                           losses=losses)\n",
    "            print('Losses', losses)\n",
    "\n",
    "    # test the trained model\n",
    "    test_text = ' I have included deaths certified as from Diarrhoea alone, or in combination with some other cause of ill defined nature; and also deaths certified as from Epidemic Enteritis, Zymotic Enteritis, Epidemic Diarrhoea, Summer Diarrhoea, Dysentery and Dysenteric diarrhoea, Choleraic Diarrhoea, Cholera, Cholera Nostras, (in the absence of Asiatic Cholera), 10 According to the previous methods of classification I could have shown a marked diminution in the number of deaths from Diarrhoea, but the method as now suggested is more satisfactory.'\n",
    "    doc = nlp(test_text)\n",
    "    print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label_, ent.text)\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path('output_dir')\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.meta['name'] = new_model_name  # rename model\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        doc2 = nlp2(test_text)\n",
    "        for ent in doc2.ents:\n",
    "            print(ent.label_, ent.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Losses {'ner': 1387.8690509796143}\n",
      "Losses {'ner': 398.28905057907104}\n",
      "Losses {'ner': 106.6355249478338}\n",
      "Losses {'ner': 63.06028253759854}\n",
      "Losses {'ner': 70.9119262383499}\n",
      "Losses {'ner': 57.94399209912462}\n",
      "Losses {'ner': 111.4920801589833}\n",
      "Losses {'ner': 71.88125707020441}\n",
      "Losses {'ner': 85.45086969149997}\n",
      "Losses {'ner': 77.80551897608075}\n",
      "Entities in ' I have included deaths certified as from Diarrhoea alone, or in combination with some other cause of ill defined nature; and also deaths certified as from Epidemic Enteritis, Zymotic Enteritis, Epidemic Diarrhoea, Summer Diarrhoea, Dysentery and Dysenteric diarrhoea, Choleraic Diarrhoea, Cholera, Cholera Nostras, (in the absence of Asiatic Cholera), 10 According to the previous methods of classification I could have shown a marked diminution in the number of deaths from Diarrhoea, but the method as now suggested is more satisfactory.'\n",
      "Disease Diarrhoea\n",
      "Disease Epidemic Enteritis,\n",
      "Disease Zymotic Enteritis\n",
      "Disease Epidemic Diarrhoea\n",
      "Disease Summer Diarrhoea\n",
      "Disease Dysenteric\n",
      "Disease Choleraic Diarrhoea\n",
      "Disease Cholera\n",
      "Disease Nostras\n",
      "Saved model to output_dir\n",
      "Loading from output_dir\n",
      "Disease Diarrhoea\n",
      "Disease Epidemic Enteritis,\n",
      "Disease Zymotic Enteritis\n",
      "Disease Epidemic Diarrhoea\n",
      "Disease Summer Diarrhoea\n",
      "Disease Dysenteric\n",
      "Disease Choleraic Diarrhoea\n",
      "Disease Cholera\n",
      "Disease Nostras\n"
     ]
    }
   ],
   "source": [
    "# Train our model on our training data \n",
    "train_ner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our new NER model \n",
    "output_dir = Path('output_dir')\n",
    "nlp2 = spacy.load(output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Testing here is done 'by eye' we need to test the model properly with a validation set to do get a proper metric for how well it is performing on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease DURING THE\n",
      "Disease GEORGE PADDOCK\n",
      "Disease Membranous Croup\n",
      "Disease ) 23\n",
      "Disease Whooping Cough\n",
      "Disease Small Pox\n",
      "Disease Hospitals\n",
      "Disease Respiratory Diseases\n",
      "Disease Inhabited Houses\n",
      "Disease Births,\n",
      "Disease Deaths,\n",
      "Disease and Marriages\n",
      "Disease Annual\n",
      "Disease Deaths\n",
      "Disease Street List\n",
      "Disease James Westminster\n",
      "Disease Hampstead\n",
      "Disease Plumstead\n",
      "Disease St. George\n",
      "Disease Old\n",
      "Disease Strand\n",
      "Disease Southwark\n",
      "Disease St. Luke\n",
      "Disease 4\n",
      "Disease St. George\n",
      "Disease these\n",
      "Disease Poplar,\n",
      "Disease St.\n",
      "Disease Saviour\n",
      "Disease St. George\n",
      "Disease Southwark\n",
      "Disease Whitechapel\n",
      "Disease Diarrhoea\n",
      "Disease 328\n",
      "Disease Pancras\n",
      "Disease Dietic Diseases\n",
      "Disease 23\n",
      "Disease 0.07\n",
      "Disease 0.01\n",
      "Disease 2\n",
      "Disease VII.—\n",
      "Disease 0.11 0.02\n",
      "Disease Deaths Registered\n",
      "Disease Metropolitan Sanitary\n",
      "Disease Bethnal Green,\n",
      "Disease Diseases\n",
      "Disease , Ages,\n",
      "Disease 65 &\n",
      "Disease Membranous Croup\n",
      "Disease Measles\n",
      "Disease Whooping Cough\n",
      "Disease Diarrhoea\n",
      "Disease Rheumatic Fever\n",
      "Disease 2\n",
      "Disease Deaths\n",
      "Disease Small Pox\n",
      "Disease 7\n",
      "Disease Measles\n",
      "Disease Scarlet Fever\n",
      "Disease Typhus Fever\n",
      "Disease Enteric Fever 26\n",
      "Disease Simple Fever\n",
      "Disease Diarrhœa 54\n",
      "Disease Small\n",
      "Disease Pox 1.11\n",
      "Disease Measles\n",
      "Disease Diphtheria\n",
      "Disease 29.55 „ „\n",
      "Disease Whooping Cough\n",
      "Disease „ 6.43\n",
      "Disease Typhus Fever\n",
      "Disease Simple Fever\n",
      "Disease Diarrhoea\n",
      "Disease Dr. Goodall\n",
      "Disease Medical\n",
      "Disease Small Pox\n",
      "Disease Diphtheria\n",
      "Disease & Membranous\n",
      "Disease Typhoid.\n",
      "Disease Small Pox\n",
      "Disease Small Pox\n",
      "Disease the\n",
      "Disease Scarlet Fever\n",
      "Disease deaths\n",
      "Disease Diarrhoea\n",
      "Disease Dysentery 32\n",
      "Disease Malarial\n",
      "Disease Remittent Fever\n",
      "Disease Zoogenous Diseases\n",
      "Disease Gonorrhoea\n",
      "Disease Dietic\n",
      "Disease Diseases !\n",
      "Disease .1 Want\n",
      "Disease Croup\n",
      "Disease 2\n",
      "Disease Sore Throat,\n",
      "Disease Diseases (\n",
      "Disease 2\n",
      "Disease (Continued\n",
      "Disease .\n",
      "Disease (\n",
      "Disease Debility\n",
      "Disease Hæmorrhage\n",
      "Disease 2\n",
      "Disease Sudden Death\n",
      "Disease TABLE\n",
      "Disease Diseases\n",
      "Disease Deaths\n",
      "Disease Wasting Diseases\n",
      "Disease Convulsive Diseases\n",
      "Disease Includes\n",
      "Disease Small Pox\n",
      "Disease ,\n",
      "Disease 5;\n",
      "Disease Measles\n",
      "Disease ,\n",
      "Disease 135;\n",
      "Disease Scarlet Fever,\n",
      "Disease 27;\n",
      "Disease Diphtheria\n",
      "Disease , 133\n",
      "Disease ; Whooping\n",
      "Disease ; Fever\n",
      "Disease Diarrhrea\n",
      "Disease Bronchitis\n",
      "Disease Disease,\n",
      "Disease Laryngitis\n",
      "Disease Croup\n",
      "Disease Phthisis\n",
      "Disease 225;\n",
      "Disease Scrofula\n",
      "Disease Rickets\n",
      "Disease Infantile\n",
      "Disease Convulsions\n",
      "Disease Teething\n",
      "Disease Small Pox\n",
      "Disease 7 13.5\n",
      "Disease 1.9 Measles\n",
      "Disease Diphtheria 14\n",
      "Disease Whooping Cough\n",
      "Disease Stagnant Water\n",
      "Disease Animal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bethnal_green = open('Full_text/BethnalGreen.1894.b17997689.txt').read()\n",
    "doc3 = nlp2(bethnal_green)\n",
    "for ent in doc3.ents:\n",
    "            print(ent.label_, ent.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ner]",
   "language": "python",
   "name": "conda-env-ner-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
